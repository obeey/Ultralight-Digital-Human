#!/usr/bin/env python3
"""
æ•°å­—äººæ®µè½ç”Ÿæˆç³»ç»Ÿ - æŒ‰æ®µè½è¿ç»­ç”Ÿæˆ
ç›´æ¥ä½¿ç”¨DeepSeekè¿”å›çš„å®Œæ•´æ®µè½ï¼Œè®©TTSè‡ªå·±å¤„ç†åˆ†å‰²
"""

import os
import sys
import time
import json
import threading
import queue
import subprocess
import requests
import logging
import random
import hashlib
from datetime import datetime
from dataclasses import dataclass
from typing import List, Dict, Any, Optional

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S%f'
)
logger = logging.getLogger(__name__)

@dataclass
class DigitalHumanConfig:
    """æ•°å­—äººç³»ç»Ÿé…ç½®"""
    # TTSé…ç½®
    tts_url: str = "http://127.0.0.1:9880/tts"
    reference_audio: str = "/mnt/e/CYC/projects/live-selling/assets/250911/reference.FLAC"
    reference_text: str = "å®å®ï¼Œå…ˆè®©æˆ‘ä»¬ç‚¹å‡»å³ä¸‹è§’å°é»„è½¦é‡Œå¤´ï¼Œæ‚¨ç‚¹å‡»ä»»æ„ä¸€ä¸ªé“¾æ¥ç‚¹è¿›å»ä»¥å"
    
    # æ¨ç†é…ç½®
    checkpoint_path: str = "checkpoint/195.pth"
    dataset_path: str = "input/mxbc_0913/"
    
    # DeepSeeké…ç½®
    product_info: str = "èœœé›ªå†°åŸä¼˜æƒ åˆ¸"
    auto_start: bool = True
    
    # æ®µè½ç”Ÿæˆé…ç½®
    paragraph_length: int = 200  # æ¯æ®µè¯æœ¯é•¿åº¦ï¼ˆå­—ç¬¦æ•°ï¼‰
    paragraph_interval: float = 60.0  # æ®µè½ç”Ÿæˆé—´éš”ï¼ˆç§’ï¼‰
    
    # å¹¶è¡Œé…ç½®
    parallel_workers: int = 2
    text_queue_size: int = 50
    video_queue_size: int = 10
    
    @classmethod
    def from_config_file(cls, config_path: str = "config.json"):
        """ä»é…ç½®æ–‡ä»¶åŠ è½½"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config_data = f.read()
                if not config_data.strip():
                    logger.warning(f"é…ç½®æ–‡ä»¶ {config_path} ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                    return cls()
                
                config_dict = json.loads(config_data)
                # å¿½ç•¥ deepseek_api_keyï¼Œä»ç¯å¢ƒå˜é‡è¯»å–
                config_dict.pop('deepseek_api_key', None)
                return cls(**config_dict)
        except FileNotFoundError:
            logger.warning(f"é…ç½®æ–‡ä»¶ {config_path} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return cls()
        except json.JSONDecodeError as e:
            logger.error(f"é…ç½®æ–‡ä»¶ {config_path} æ ¼å¼é”™è¯¯: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return cls()
        except Exception as e:
            logger.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return cls()

class DeepSeekClient:
    """DeepSeek APIå®¢æˆ·ç«¯"""
    
    def __init__(self):
        self.api_key = os.environ.get("DEEPSEEK_API_KEY")
        if not self.api_key:
            logger.error("æœªè®¾ç½®ç¯å¢ƒå˜é‡ DEEPSEEK_API_KEYï¼Œå°†ä½¿ç”¨å¤‡ç”¨è¯æœ¯")
        
        self.base_url = "https://api.deepseek.com/v1/chat/completions"
        self.headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}" if self.api_key else ""
        }
    
    def generate_paragraph_script(self, product_info: str, paragraph_length: int = 200) -> str:
        """ç”Ÿæˆæ®µè½è¯æœ¯"""
        if not self.api_key:
            return self._get_fallback_paragraph(product_info)
        
        try:
            prompt = f"""
è¯·ä¸º"{product_info}"ç”Ÿæˆä¸€æ®µç›´æ’­å¸¦è´§è¯æœ¯ï¼Œè¦æ±‚ï¼š
1. é•¿åº¦çº¦{paragraph_length}å­—ç¬¦
2. å†…å®¹è¿è´¯ï¼Œè¯­è¨€ç”ŸåŠ¨
3. åŒ…å«äº§å“ä»‹ç»ã€ä¼˜æƒ ä¿¡æ¯ã€è´­ä¹°å¼•å¯¼
4. è¯­æ°”äº²åˆ‡è‡ªç„¶ï¼Œé€‚åˆç›´æ’­åœºæ™¯
5. ä¸è¦ä½¿ç”¨æ ‡ç‚¹ç¬¦å·åˆ†æ®µï¼Œè®©è¯­éŸ³æ›´è¿è´¯
6. ç›´æ¥è¿”å›è¯æœ¯å†…å®¹ï¼Œä¸è¦å…¶ä»–è¯´æ˜

äº§å“ä¿¡æ¯ï¼š{product_info}
"""
            
            data = {
                "model": "deepseek-chat",
                "messages": [
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.8,
                "max_tokens": 500
            }
            
            response = requests.post(
                self.base_url,
                headers=self.headers,
                json=data,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                content = result['choices'][0]['message']['content'].strip()
                # æ¸…ç†å¯èƒ½çš„å¼•å·å’Œå¤šä½™ç©ºæ ¼
                content = content.replace('"', '').replace("'", '').strip()
                logger.info(f"DeepSeekç”Ÿæˆæ®µè½è¯æœ¯æˆåŠŸï¼Œé•¿åº¦: {len(content)}å­—ç¬¦")
                return content
            else:
                logger.error(f"DeepSeek APIè¯·æ±‚å¤±è´¥: {response.status_code}")
                return self._get_fallback_paragraph(product_info)
                
        except Exception as e:
            logger.error(f"DeepSeek APIè°ƒç”¨å¼‚å¸¸: {e}")
            return self._get_fallback_paragraph(product_info)
    
    def _get_fallback_paragraph(self, product_info: str) -> str:
        """å¤‡ç”¨æ®µè½è¯æœ¯"""
        fallback_paragraphs = [
            f"å®å®ä»¬{product_info}è¶…å€¼ä¼˜æƒ æ¥å•¦ç°åœ¨ä¸‹å•ç«‹äº«æŠ˜æ‰£ä¼˜æƒ è¿™ä¸ªä»·æ ¼çœŸçš„å¤ªåˆ’ç®—äº†æ•°é‡æœ‰é™å…ˆåˆ°å…ˆå¾—å–œæ¬¢çš„å®å­èµ¶ç´§ç‚¹å‡»å°é»„è½¦ä¸‹å•å§é”™è¿‡å°±æ²¡æœ‰äº†è¿™ä¹ˆå¥½çš„æœºä¼šä¸è¦çŠ¹è±«äº†ç«‹åˆ»æŠ¢è´­",
            f"å„ä½å®å®æ³¨æ„äº†{product_info}é™æ—¶ç‰¹ä»·æ´»åŠ¨å¼€å§‹äº†åŸä»·è¦å‡ åå—ç°åœ¨åªè¦è¿™ä¸ªä»·æ ¼çœŸçš„æ˜¯ç™½èœä»·äº†è´¨é‡ç»å¯¹ä¿è¯å¤§å®¶æ”¾å¿ƒè´­ä¹°ç‚¹å‡»å³ä¸‹è§’å°é»„è½¦ç«‹åˆ»ä¸‹å•äº«å—ä¼˜æƒ ä»·æ ¼",
            f"å®å®ä»¬çœ‹è¿‡æ¥{product_info}ä»Šå¤©ç‰¹åˆ«ä¼˜æƒ æ´»åŠ¨è¿™ä¸ªäº§å“å¹³æ—¶å¾ˆéš¾ä¹°åˆ°ä»Šå¤©ç»™å¤§å®¶äº‰å–åˆ°äº†æœ€ä½ä»·æ ¼æœºä¼šéš¾å¾—æ•°é‡çœŸçš„ä¸å¤šäº†å–œæ¬¢çš„å®å­æŠ“ç´§æ—¶é—´ä¸‹å•ä¸è¦é”™è¿‡è¿™ä¸ªå¥½æœºä¼š",
            f"äº²çˆ±çš„å®å®ä»¬{product_info}è¶…çº§åˆ’ç®—çš„ä»·æ ¼æ¥äº†è¿™ä¸ªè´¨é‡è¿™ä¸ªä»·æ ¼çœŸçš„æ‰¾ä¸åˆ°ç¬¬äºŒå®¶äº†ç°åœ¨ä¸‹å•è¿˜æœ‰é¢å¤–ä¼˜æƒ èµ å“ç›¸é€ç‚¹å‡»å°é»„è½¦é©¬ä¸ŠæŠ¢è´­åº“å­˜ä¸å¤šå”®å®Œå³æ­¢",
            f"å®å­ä»¬{product_info}çˆ†æ¬¾æ¨èè¿™ä¸ªäº§å“é”€é‡è¶…é«˜å¥½è¯„å¦‚æ½®ç°åœ¨æ´»åŠ¨ä»·æ ¼çœŸçš„å¤ªä¼˜æƒ äº†å¹³æ—¶ä¹°ä¸åˆ°è¿™ä¸ªä»·æ ¼ä»Šå¤©ç»™å¤§å®¶æœ€å¤§çš„ä¼˜æƒ åŠ›åº¦èµ¶ç´§ä¸‹å•æŠ¢è´­å§"
        ]
        selected = random.choice(fallback_paragraphs)
        logger.info(f"ä½¿ç”¨å¤‡ç”¨æ®µè½è¯æœ¯ï¼Œé•¿åº¦: {len(selected)}å­—ç¬¦")
        return selected

class ActionManager:
    """æ™ºèƒ½åŠ¨ä½œç®¡ç†å™¨"""
    
    def __init__(self, total_images: int = 1178):
        self.total_images = total_images
        self.action_types = {
            'greeting': [(0, 150), (500, 650)],      # é—®å€™åŠ¨ä½œ
            'pointing': [(150, 300), (800, 950)],    # æŒ‡å‘åŠ¨ä½œ  
            'excited': [(300, 450), (950, 1100)],    # å…´å¥‹åŠ¨ä½œ
            'explaining': [(450, 600), (1100, 1177)], # è§£é‡ŠåŠ¨ä½œ
            'urging': [(600, 750), (200, 350)]       # å‚¬ä¿ƒåŠ¨ä½œ
        }
        
        self.keywords = {
            'greeting': ['å®å®', 'å¤§å®¶', 'å„ä½', 'äº²çˆ±', 'æœ‹å‹ä»¬', 'å®å­'],
            'pointing': ['ç‚¹å‡»', 'å°é»„è½¦', 'é“¾æ¥', 'å³ä¸‹è§’', 'è¿™é‡Œ', 'çœ‹è¿™'],
            'excited': ['ä¼˜æƒ ', 'ç‰¹ä»·', 'é™æ—¶', 'æŠ¢è´­', 'è¶…å€¼', 'åˆ’ç®—', 'ä¾¿å®œ'],
            'explaining': ['äº§å“', 'è´¨é‡', 'æè´¨', 'åŠŸèƒ½', 'æ•ˆæœ', 'ä»‹ç»'],
            'urging': ['èµ¶ç´§', 'å¿«ç‚¹', 'é©¬ä¸Š', 'ç«‹åˆ»', 'é”™è¿‡', 'æ•°é‡æœ‰é™', 'å”®å®Œ']
        }
    
    def analyze_text_action(self, text: str) -> str:
        """åˆ†ææ–‡æœ¬å†…å®¹ï¼Œè¿”å›æœ€é€‚åˆçš„åŠ¨ä½œç±»å‹"""
        action_scores = {action_type: 0 for action_type in self.action_types}
        
        # è®¡ç®—æ¯ç§åŠ¨ä½œç±»å‹çš„åŒ¹é…åˆ†æ•°
        for action_type, keywords in self.keywords.items():
            for keyword in keywords:
                if keyword in text:
                    action_scores[action_type] += 1
        
        # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„åŠ¨ä½œç±»å‹
        best_action = max(action_scores, key=action_scores.get)
        
        # å¦‚æœæ²¡æœ‰åŒ¹é…çš„å…³é”®è¯ï¼Œéšæœºé€‰æ‹©
        if action_scores[best_action] == 0:
            best_action = random.choice(list(self.action_types.keys()))
        
        logger.info(f"æ–‡æœ¬'{text[:20]}...' åŒ¹é…åŠ¨ä½œç±»å‹: {best_action}")
        return best_action
    
    def get_action_range(self, action_type: str) -> tuple:
        """è·å–åŠ¨ä½œç±»å‹å¯¹åº”çš„å›¾ç‰‡èŒƒå›´"""
        ranges = self.action_types.get(action_type, [(0, 100)])
        selected_range = random.choice(ranges)
        logger.info(f"é€‰æ‹©åŠ¨ä½œèŒƒå›´: {selected_range[0]}-{selected_range[1]} ({action_type})")
        return selected_range

class DigitalHumanGenerator:
    """æ•°å­—äººç”Ÿæˆå™¨"""
    
    def __init__(self, config: DigitalHumanConfig):
        self.config = config
        self.action_manager = ActionManager()
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs("output", exist_ok=True)
        os.makedirs("temp", exist_ok=True)
        
        # çº¿ç¨‹å®‰å…¨çš„è®¡æ•°å™¨
        self.counter_lock = threading.Lock()
        self.video_counter = 0
        self.completed_videos = []
    
    def generate_paragraph_audio(self, text: str, base_name: str) -> str:
        """ç”Ÿæˆæ®µè½éŸ³é¢‘"""
        audio_path = f"temp/{base_name}.wav"
        
        try:
            # ä½¿ç”¨TTS APIç”ŸæˆéŸ³é¢‘ï¼Œè®©TTSè‡ªå·±å¤„ç†æ–‡æœ¬åˆ†å‰²
            data = {
                "text": text,
                "text_lang": "zh",
                "ref_audio_path": self.config.reference_audio,
                "prompt_text": self.config.reference_text,
                "prompt_lang": "zh",
                "text_split_method": "cut5",  # è®©TTSè‡ªå·±åˆ†å‰²
                "batch_size": 1,
                "speed_factor": 1.0,
                "streaming_mode": False,
                "parallel_infer": True,
                "repetition_penalty": 1.35
            }
            
            response = requests.post(
                self.config.tts_url,
                json=data,
                timeout=60
            )
            
            if response.status_code == 200:
                with open(audio_path, 'wb') as f:
                    f.write(response.content)
                logger.info(f"æ®µè½TTSéŸ³é¢‘ç”ŸæˆæˆåŠŸ: {audio_path}")
                return audio_path
            else:
                logger.error(f"TTSè¯·æ±‚å¤±è´¥: {response.status_code}")
                return None
                
        except Exception as e:
            logger.error(f"TTSç”Ÿæˆå¤±è´¥: {e}")
            return None
    
    def generate_video(self, audio_path: str, text: str, base_name: str) -> Optional[str]:
        """ç”Ÿæˆæ•°å­—äººè§†é¢‘"""
        try:
            # æ­¥éª¤1: æå–HuBERTç‰¹å¾
            logger.info("æ­¥éª¤1: æå–HuBERTç‰¹å¾...")
            hubert_output_path = f"temp/{base_name}_hu.npy"
            
            cmd = ["python3", "data_utils/hubert.py", "--wav", audio_path]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)
            
            if result.returncode != 0:
                logger.error(f"HuBERTç‰¹å¾æå–å¤±è´¥: {result.stderr}")
                return None
            
            if not os.path.exists(hubert_output_path):
                logger.error(f"HuBERTç‰¹å¾æ–‡ä»¶æœªç”Ÿæˆ: {hubert_output_path}")
                return None
            
            logger.info(f"HuBERTç‰¹å¾æå–æˆåŠŸ: {hubert_output_path}")
            
            # æ­¥éª¤2: æ™ºèƒ½æ•°å­—äººæ¨ç†
            logger.info("æ­¥éª¤2: ç”Ÿæˆæ•°å­—äººè§†é¢‘...")
            video_path = f"temp/{base_name}_video.mp4"
            
            # åˆ†ææ–‡æœ¬é€‰æ‹©åŠ¨ä½œ
            action_type = self.action_manager.analyze_text_action(text)
            action_range = self.action_manager.get_action_range(action_type)
            
            # åˆ›å»ºæ™ºèƒ½æ¨ç†è„šæœ¬
            smart_script_path = self._create_smart_inference_script(
                hubert_output_path, video_path, action_range, base_name
            )
            
            # è¿è¡Œæ™ºèƒ½æ¨ç†
            cmd = ["python3", smart_script_path]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=180)
            
            if result.returncode != 0:
                logger.error(f"æ™ºèƒ½æ•°å­—äººæ¨ç†å¤±è´¥: {result.stderr}")
                return None
            
            if not os.path.exists(video_path):
                logger.error(f"æ•°å­—äººè§†é¢‘æœªç”Ÿæˆ: {video_path}")
                return None
            
            logger.info(f"æ•°å­—äººè§†é¢‘ç”ŸæˆæˆåŠŸ: {video_path}")
            
            # æ­¥éª¤3: åˆå¹¶è§†é¢‘å’ŒéŸ³é¢‘
            logger.info("æ­¥éª¤3: åˆå¹¶è§†é¢‘å’ŒéŸ³é¢‘...")
            final_video_path = f"output/paragraph_{base_name}.mp4"
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(final_video_path), exist_ok=True)
            
            cmd = [
                "ffmpeg", "-y",
                "-i", video_path,
                "-i", audio_path,
                "-c:v", "copy",
                "-c:a", "aac",
                "-b:a", "128k",
                "-ar", "32000",
                "-ac", "1",
                "-shortest",
                final_video_path
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
            
            if result.returncode != 0:
                logger.error(f"è§†é¢‘éŸ³é¢‘åˆå¹¶å¤±è´¥: {result.stderr}")
                return None
            
            # éªŒè¯æœ€ç»ˆæ–‡ä»¶
            if os.path.exists(final_video_path):
                file_size = os.path.getsize(final_video_path)
                logger.info(f"âœ… æ•°å­—äººæ®µè½è§†é¢‘ç”Ÿæˆå®Œæˆ: {final_video_path} (å¤§å°: {file_size} å­—èŠ‚)")
                
                # æ¸…ç†ä¸­é—´æ–‡ä»¶
                self.cleanup_intermediate_files(audio_path, hubert_output_path, video_path, smart_script_path)
                logger.info(f"å·²æ¸…ç†ä¸­é—´æ–‡ä»¶ï¼Œä¿ç•™æœ€ç»ˆè§†é¢‘: {final_video_path}")
                
                return final_video_path
            else:
                logger.error("æœ€ç»ˆè§†é¢‘æ–‡ä»¶æœªç”Ÿæˆ")
                return None
                
        except Exception as e:
            logger.error(f"æ•°å­—äººè§†é¢‘ç”Ÿæˆå¤±è´¥: {e}")
            return None
    
    def _create_smart_inference_script(self, hubert_path: str, video_path: str, action_range: tuple, base_name: str) -> str:
        """åˆ›å»ºæ™ºèƒ½æ¨ç†è„šæœ¬"""
        script_path = f"temp/smart_inference_{base_name}.py"
        
        start_idx, end_idx = action_range
        action_range_size = end_idx - start_idx + 1
        
        script_content = f'''#!/usr/bin/env python3
"""
æ™ºèƒ½æ•°å­—äººæ¨ç†è„šæœ¬ - åŠ¨ä½œèŒƒå›´: {start_idx}-{end_idx}
"""

import sys
import os
import numpy as np
import torch
import cv2

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„ï¼Œè§£å†³æ¨¡å—å¯¼å…¥é—®é¢˜
project_root = os.path.dirname(os.path.abspath(__file__))
if project_root.endswith('/temp'):
    project_root = os.path.dirname(project_root)
sys.path.insert(0, project_root)
os.chdir(project_root)

from unet import Model

# è®¾å¤‡é…ç½®
device = 'cuda' if torch.cuda.is_available() else 'cpu'

def get_audio_features(features, index):
    """è·å–éŸ³é¢‘ç‰¹å¾ - ä¸åŸå§‹inference.pyç›¸åŒçš„é€»è¾‘"""
    left = index - 4
    right = index + 4
    pad_left = 0
    pad_right = 0
    if left < 0:
        pad_left = -left
        left = 0
    if right > features.shape[0]:
        pad_right = right - features.shape[0]
        right = features.shape[0]
    auds = torch.from_numpy(features[left:right])
    if pad_left > 0:
        auds = torch.cat([torch.zeros_like(auds[:pad_left]), auds], dim=0)
    if pad_right > 0:
        auds = torch.cat([auds, torch.zeros_like(auds[:pad_right])], dim=0)
    return auds

# åŠ è½½æ¨¡å‹ - ä½¿ç”¨æ­£ç¡®çš„åŠ è½½æ–¹å¼
net = Model(6, "hubert").to(device)
net.load_state_dict(torch.load("{self.config.checkpoint_path}", map_location=device))
net.eval()

# åŠ è½½HuBERTç‰¹å¾
audio_feats = np.load("{hubert_path}")
print(f"åŠ è½½HuBERTç‰¹å¾: {{audio_feats.shape}}")

# æ•°æ®é›†è·¯å¾„
dataset_dir = "{self.config.dataset_path}"
img_dir = os.path.join(dataset_dir, "full_body_img/")
lms_dir = os.path.join(dataset_dir, "landmarks/")

# æ™ºèƒ½åŠ¨ä½œé€‰æ‹©å‚æ•°
action_start = {start_idx}
action_end = {end_idx}
action_range_size = {action_range_size}

print(f"ä½¿ç”¨åŠ¨ä½œèŒƒå›´: {{action_start}}-{{action_end}}")

# è·å–ç¤ºä¾‹å›¾ç‰‡å°ºå¯¸
exm_img = cv2.imread(img_dir + "0.jpg")
h, w = exm_img.shape[:2]

# åˆ›å»ºè§†é¢‘å†™å…¥å™¨
video_writer = cv2.VideoWriter("{video_path}", cv2.VideoWriter_fourcc('M','J','P', 'G'), 25, (w, h))

# ç”Ÿæˆè§†é¢‘å¸§
for i in range(audio_feats.shape[0]):
    # æ™ºèƒ½åŠ¨ä½œé€‰æ‹©ï¼šåœ¨æŒ‡å®šèŒƒå›´å†…å¾ªç¯
    if action_range_size > 1:
        cycle_pos = i % (action_range_size * 2 - 2) if action_range_size > 1 else 0
        if cycle_pos < action_range_size:
            img_idx = action_start + cycle_pos
        else:
            img_idx = action_start + (action_range_size * 2 - 2 - cycle_pos)
    else:
        img_idx = action_start
    
    # ç¡®ä¿ç´¢å¼•åœ¨æœ‰æ•ˆèŒƒå›´å†…
    img_idx = max(0, min(img_idx, 1177))  # 0-1177èŒƒå›´
    
    # æ„å»ºæ–‡ä»¶è·¯å¾„
    img_path = img_dir + str(img_idx) + '.jpg'
    lms_path = lms_dir + str(img_idx) + '.lms'
    
    # åŠ è½½å›¾ç‰‡å’Œlandmarks
    img = cv2.imread(img_path)
    img_h, img_w = img.shape[:2]
    
    # è¯»å–landmarks
    lms_list = []
    with open(lms_path, "r") as f:
        lines = f.read().splitlines()
        for line in lines:
            arr = line.split(" ")
            if len(arr) != 2:
                continue
            arr = np.array(arr, dtype=np.float32)
            lms_list.append(arr)
    
    if len(lms_list) < 10:
        print(f"Warning: Insufficient landmarks in {{lms_path}}: got {{len(lms_list)}}, skipping frame")
        continue
        
    lms = np.array(lms_list, dtype=np.int32)
    
    # ä½¿ç”¨ä¸è®­ç»ƒæ—¶ç›¸åŒçš„è£å‰ªé€»è¾‘
    all_x = lms[:, 0]
    all_y = lms[:, 1]
    
    xmin = np.min(all_x)
    xmax = np.max(all_x)
    ymin = np.min(all_y)
    ymax = np.max(all_y)
    
    # Add some padding and make it square
    width = xmax - xmin
    height = ymax - ymin
    size = max(width, height)
    
    # Center the crop
    center_x = (xmin + xmax) // 2
    center_y = (ymin + ymax) // 2
    
    # Add 20% padding
    size = int(size * 1.2)
    
    xmin = center_x - size // 2
    ymin = center_y - size // 2
    xmax = xmin + size
    ymax = ymin + size
    
    # Ensure crop coordinates are within image bounds
    xmin = max(0, xmin)
    ymin = max(0, ymin)
    xmax = min(img_w, xmax)
    ymax = min(img_h, ymax)
    
    # Validate crop coordinates
    width = xmax - xmin
    height = ymax - ymin
    if width <= 0 or height <= 0:
        print(f"Warning: Invalid crop dimensions for frame {{i}}: width={{width}}, height={{height}}, skipping")
        continue
    
    crop_img = img[ymin:ymax, xmin:xmax]
    
    # Check if crop_img is valid
    if crop_img.size == 0 or crop_img.shape[0] == 0 or crop_img.shape[1] == 0:
        print(f"Warning: Empty crop image for frame {{i}}, skipping")
        continue
        
    h_crop, w_crop = crop_img.shape[:2]
    crop_img = cv2.resize(crop_img, (168, 168), cv2.INTER_AREA)
    crop_img_ori = crop_img.copy()
    img_real_ex = crop_img[4:164, 4:164].copy()
    img_real_ex_ori = img_real_ex.copy()
    img_masked = cv2.rectangle(img_real_ex_ori,(5,5,150,145),(0,0,0),-1)
    
    img_masked = img_masked.transpose(2,0,1).astype(np.float32)
    img_real_ex = img_real_ex.transpose(2,0,1).astype(np.float32)
    
    img_real_ex_T = torch.from_numpy(img_real_ex / 255.0).to(device)
    img_masked_T = torch.from_numpy(img_masked / 255.0).to(device)  
    img_concat_T = torch.cat([img_real_ex_T, img_masked_T], axis=0)[None]
    
    # è·å–éŸ³é¢‘ç‰¹å¾
    audio_feat = get_audio_features(audio_feats, i)
    audio_feat = audio_feat.reshape(16,32,32)
    audio_feat = audio_feat[None]
    audio_feat = audio_feat.to(device)
    img_concat_T = img_concat_T.to(device)
    
    # æ¨ç†ç”Ÿæˆ
    with torch.no_grad():
        pred = net(img_concat_T, audio_feat)[0]
        
    pred = pred.cpu().numpy().transpose(1,2,0)*255
    pred = np.array(pred, dtype=np.uint8)
    crop_img_ori[4:164, 4:164] = pred
    crop_img_ori = cv2.resize(crop_img_ori, (w_crop, h_crop))
    img[ymin:ymax, xmin:xmax] = crop_img_ori
    
    # å†™å…¥è§†é¢‘
    video_writer.write(img)
    
    if i % 50 == 0:
        print(f"å·²å¤„ç†å¸§: {{i+1}}/{{len(audio_feats)}}, å½“å‰åŠ¨ä½œå›¾ç‰‡: {{img_idx}}")

video_writer.release()
print(f"æ™ºèƒ½æ•°å­—äººè§†é¢‘ç”Ÿæˆå®Œæˆ: {video_path}")
'''
        
        with open(script_path, 'w', encoding='utf-8') as f:
            f.write(script_content)
        
        logger.info(f"åˆ›å»ºæ™ºèƒ½æ¨ç†è„šæœ¬: {script_path} (åŠ¨ä½œèŒƒå›´: {start_idx}-{end_idx})")
        return script_path
    
    def cleanup_intermediate_files(self, audio_path: str, hubert_path: str, video_path: str, script_path: str):
        """æ¸…ç†ä¸­é—´æ–‡ä»¶"""
        files_to_clean = [audio_path, hubert_path, video_path, script_path]
        for file_path in files_to_clean:
            try:
                if os.path.exists(file_path):
                    os.remove(file_path)
            except Exception as e:
                logger.warning(f"æ¸…ç†æ–‡ä»¶å¤±è´¥ {file_path}: {e}")

class DigitalHumanParagraphSystem:
    """æ•°å­—äººæ®µè½ç”Ÿæˆç³»ç»Ÿ"""
    
    def __init__(self):
        self.config = DigitalHumanConfig.from_config_file()
        self.deepseek_client = DeepSeekClient()
        self.generator = DigitalHumanGenerator(self.config)
        
        # é˜Ÿåˆ—å’Œçº¿ç¨‹ç®¡ç†
        self.text_queue = queue.Queue(maxsize=self.config.text_queue_size)
        self.running = False
        
        # çº¿ç¨‹
        self.script_thread = None
        self.video_threads = []
        
        # ç»Ÿè®¡
        self.start_time = None
        self.completed_count = 0
        self.completed_lock = threading.Lock()
    
    def start(self, product_info: str = None):
        """å¯åŠ¨ç³»ç»Ÿ"""
        if product_info is None:
            product_info = self.config.product_info
        
        logger.info("å¯åŠ¨æ•°å­—äººæ®µè½ç”Ÿæˆç³»ç»Ÿ...")
        
        # æ£€æŸ¥å¿…è¦æ–‡ä»¶
        required_files = [
            self.config.reference_audio,
            self.config.checkpoint_path,
            "data_utils/hubert.py",
            "inference.py"
        ]
        
        for file_path in required_files:
            if not os.path.exists(file_path):
                logger.error(f"å¿…è¦æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                return False
        
        logger.info("âœ… æ‰€æœ‰å¿…è¦æ–‡ä»¶æ£€æŸ¥é€šè¿‡")
        
        # è®¾ç½®è¿è¡Œæ ‡å¿—
        self.running = True
        self.start_time = time.time()
        
        # å¯åŠ¨æ®µè½ç”Ÿæˆçº¿ç¨‹
        self.script_thread = threading.Thread(
            target=self._paragraph_generation_worker, 
            args=(product_info,), 
            daemon=True
        )
        self.script_thread.start()
        
        # å¯åŠ¨è§†é¢‘ç”Ÿæˆçº¿ç¨‹
        for i in range(self.config.parallel_workers):
            thread = threading.Thread(
                target=self._video_generation_worker,
                args=(f"video_worker_{i}",),
                daemon=True
            )
            thread.start()
            self.video_threads.append(thread)
        
        logger.info("æ•°å­—äººæ®µè½ç”Ÿæˆç³»ç»Ÿå·²å¯åŠ¨")
        
        # é¢„çƒ­ï¼šç«‹å³ç”Ÿæˆä¸€æ®µè¯æœ¯
        try:
            bootstrap_text = self.deepseek_client.generate_paragraph_script(
                product_info, self.config.paragraph_length
            )
            self.text_queue.put_nowait(bootstrap_text)
            logger.info(f"é¢„çƒ­æ®µè½å·²å…¥é˜Ÿ: {bootstrap_text[:50]}...")
        except Exception as e:
            logger.warning(f"é¢„çƒ­æ®µè½å…¥é˜Ÿå¤±è´¥: {e}")
        
        return True
    
    def _paragraph_generation_worker(self, product_info: str):
        """æ®µè½ç”Ÿæˆå·¥ä½œçº¿ç¨‹"""
        logger.info("æ®µè½ç”Ÿæˆçº¿ç¨‹å·²å¯åŠ¨")
        
        try:
            while self.running:
                try:
                    # ç”Ÿæˆæ®µè½è¯æœ¯
                    paragraph_text = self.deepseek_client.generate_paragraph_script(
                        product_info, self.config.paragraph_length
                    )
                    
                    # æ·»åŠ åˆ°é˜Ÿåˆ—
                    self.text_queue.put(paragraph_text, timeout=5.0)
                    logger.info(f"æ®µè½è¯æœ¯å·²å…¥é˜Ÿ: {paragraph_text[:50]}... (é•¿åº¦: {len(paragraph_text)}å­—ç¬¦)")
                    
                    # ç­‰å¾…ä¸‹ä¸€æ¬¡ç”Ÿæˆ
                    time.sleep(self.config.paragraph_interval)
                    
                except queue.Full:
                    logger.warning("æ–‡æœ¬é˜Ÿåˆ—å·²æ»¡ï¼Œè·³è¿‡æœ¬æ¬¡ç”Ÿæˆ")
                    time.sleep(5)
                except Exception as e:
                    logger.error(f"æ®µè½ç”Ÿæˆå¼‚å¸¸: {e}")
                    time.sleep(10)
                    
        except Exception as e:
            logger.error(f"æ®µè½ç”Ÿæˆçº¿ç¨‹å¼‚å¸¸é€€å‡º: {e}")
    
    def _video_generation_worker(self, worker_name: str):
        """è§†é¢‘ç”Ÿæˆå·¥ä½œçº¿ç¨‹"""
        logger.info(f"è§†é¢‘ç”Ÿæˆçº¿ç¨‹ {worker_name} å·²å¯åŠ¨")
        
        try:
            while self.running:
                try:
                    # ä»æ–‡æœ¬é˜Ÿåˆ—è·å–ä»»åŠ¡
                    text = self.text_queue.get(timeout=1.0)
                    logger.info(f"[{worker_name}] å–åˆ°æ®µè½è¯æœ¯: {text[:50]}... (é•¿åº¦: {len(text)}å­—ç¬¦)")
                    
                    # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
                    timestamp = int(time.time() * 1000000)
                    thread_id = threading.get_ident() % 1000
                    
                    with self.generator.counter_lock:
                        self.generator.video_counter += 1
                        current_counter = self.generator.video_counter
                    
                    base_name = f"paragraph_{current_counter:06d}_{timestamp}_{thread_id}"
                    
                    # æ­¥éª¤1: ç”Ÿæˆæ®µè½éŸ³é¢‘
                    logger.info(f"[{worker_name}] ç”Ÿæˆæ®µè½TTSéŸ³é¢‘: {text[:30]}...")
                    audio_path = self.generator.generate_paragraph_audio(text, base_name)
                    
                    if not audio_path:
                        logger.error(f"[{worker_name}] æ®µè½TTSéŸ³é¢‘ç”Ÿæˆå¤±è´¥")
                        continue
                    
                    logger.info(f"[{worker_name}] æ®µè½TTSéŸ³é¢‘ç”ŸæˆæˆåŠŸ: {audio_path}")
                    
                    # æ­¥éª¤2: ç”Ÿæˆæ•°å­—äººè§†é¢‘
                    logger.info(f"[{worker_name}] å¼€å§‹ç”Ÿæˆæ•°å­—äººæ®µè½è§†é¢‘...")
                    final_video_path = self.generator.generate_video(audio_path, text, base_name)
                    
                    if final_video_path:
                        with self.completed_lock:
                            self.completed_count += 1
                            self.generator.completed_videos.append(final_video_path)
                        
                        logger.info(f"[{worker_name}] âœ… æ®µè½è§†é¢‘ç”Ÿæˆå®Œæˆ: {final_video_path}")
                    else:
                        logger.error(f"[{worker_name}] æ®µè½è§†é¢‘ç”Ÿæˆå¤±è´¥")
                    
                    # æ ‡è®°ä»»åŠ¡å®Œæˆ
                    self.text_queue.task_done()
                    
                except queue.Empty:
                    continue
                except Exception as e:
                    logger.error(f"[{worker_name}] è§†é¢‘ç”Ÿæˆå¼‚å¸¸: {e}")
                    time.sleep(5)
                    
        except Exception as e:
            logger.error(f"è§†é¢‘ç”Ÿæˆçº¿ç¨‹ {worker_name} å¼‚å¸¸é€€å‡º: {e}")
    
    def stop(self):
        """åœæ­¢ç³»ç»Ÿ"""
        logger.info("åœæ­¢æ•°å­—äººæ®µè½ç”Ÿæˆç³»ç»Ÿ...")
        self.running = False
        
        # ç­‰å¾…çº¿ç¨‹ç»“æŸ
        if self.script_thread and self.script_thread.is_alive():
            self.script_thread.join(timeout=5)
        
        for thread in self.video_threads:
            if thread.is_alive():
                thread.join(timeout=5)
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        runtime = time.time() - self.start_time if self.start_time else 0
        logger.info(f"âœ… æœ¬æ¬¡å…±ç”Ÿæˆ {self.completed_count} ä¸ªæ•°å­—äººæ®µè½è§†é¢‘")
        logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: output")
        logger.info(f"â±ï¸ è¿è¡Œæ—¶é—´: {runtime:.1f} ç§’")
        
        logger.info("æ•°å­—äººæ®µè½ç”Ÿæˆç³»ç»Ÿå·²åœæ­¢")
    
    def run_forever(self):
        """æŒç»­è¿è¡Œ"""
        try:
            logger.info("ğŸ”„ æŒç»­è¿è¡Œä¸­ï¼ŒæŒ‰ Ctrl+C åœæ­¢")
            logger.info("--" * 25)
            
            last_report_time = time.time()
            
            while self.running:
                time.sleep(1)
                
                # æ¯åˆ†é’ŸæŠ¥å‘Šä¸€æ¬¡è¿›åº¦
                current_time = time.time()
                if current_time - last_report_time >= 60:
                    runtime_minutes = int((current_time - self.start_time) / 60)
                    logger.info(f"ç³»ç»Ÿè¿è¡Œ: {runtime_minutes} åˆ†é’Ÿï¼Œå·²å®Œæˆ {self.completed_count} ä¸ªæ•°å­—äººæ®µè½è§†é¢‘")
                    last_report_time = current_time
                    
        except KeyboardInterrupt:
            logger.info("æ”¶åˆ°ä¸­æ–­ä¿¡å·...")
        finally:
            self.stop()

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¬ æ•°å­—äººæ®µè½ç”Ÿæˆç³»ç»Ÿ")
    print("=" * 50)
    
    try:
        # åŠ è½½é…ç½®
        config = DigitalHumanConfig.from_config_file()
        logger.info(f"å·²åŠ è½½é…ç½®æ–‡ä»¶: config.json")
        
        # åˆ›å»ºç³»ç»Ÿ
        system = DigitalHumanParagraphSystem()
        
        # å¯åŠ¨ç³»ç»Ÿ
        if system.start(config.product_info):
            print(f"\nğŸš€ ç³»ç»Ÿå·²å¯åŠ¨ï¼è‡ªåŠ¨ä¸º '{config.product_info}' æŒç»­ç”Ÿæˆæ®µè½è¯æœ¯å¹¶åˆ¶ä½œè§†é¢‘")
            print(f"ğŸ“ è¾“å‡ºç›®å½•: output/")
            print(f"ğŸ“Š æ®µè½é•¿åº¦: {config.paragraph_length} å­—ç¬¦")
            print(f"â±ï¸ ç”Ÿæˆé—´éš”: {config.paragraph_interval} ç§’")
            print(f"ğŸ”„ æŒç»­è¿è¡Œä¸­ï¼ŒæŒ‰ Ctrl+C åœæ­¢")
            print("--" * 25)
            
            # æŒç»­è¿è¡Œ
            system.run_forever()
        else:
            logger.error("ç³»ç»Ÿå¯åŠ¨å¤±è´¥")
            
    except Exception as e:
        logger.error(f"ç³»ç»Ÿè¿è¡Œå¼‚å¸¸: {e}")

if __name__ == "__main__":
    main()